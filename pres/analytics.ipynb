{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print all output for a cell instead of only last one \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_analytics as ut\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Bla bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df, account_df = ut.loadData()\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esempio testo tweet originale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_df.loc[9,'tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come è possibile vedere, i tweet presentano solitamente hashtag, menzioni, url ecc.. che però difficilmente si riescono ad encodare come informazioni utili da passare in input ad una LSTM. Pertanto uno step di preprocessing è sicuramente necessario per ridurre il numero di OOV words mantenendo intatte il più possibile le informazioni che questi dati possiedono.\n",
    "\n",
    "Step di preprocessing per ogni singolo tweet:\n",
    "- 'RT' -> ' retweet '\n",
    "- '\\n' -> ' '\n",
    "- '$apple' -> ' stock '\n",
    "- '@' -> ' email '\n",
    "- '1,2,3..' -> ' number '\n",
    "- '$,£..' -> ' money '\n",
    "- '#' -> ' hashtag '\n",
    "- '@pontifex' -> ' username '\n",
    "\n",
    "- 'http,https..' -> 'url'\n",
    "- 'ahah, haha, ajaj, jaja' -> 'ahah'\n",
    "- '-' -> ' '\n",
    "- \"'\" -> \" '\"\n",
    "- Remove tweets too shorts (minimum 3 tokens required)\n",
    "\n",
    "Perchè lo facciamo così:\n",
    "- cashtag, money, emoji:\n",
    "- esclusione tweet corti: abbiamo deciso di eliminare i tweet che dopo il preprocessing possedevano un numero di token inferiore a 3. Questo ha permesso di 'pulire' il dataset da tweet poco esplicativi (anche per un umano) che avrebbero costituito degli outlier e che avrebbero peggiorato le performance\n",
    "- inglese vs altre lingue: \n",
    "- FastText vs Glove:\n",
    "\n",
    "Testo pulito:\n",
    "\n",
    "Stampare esempi testo pulito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_pickle(ut.DATA_FOLDER / 'processed_dataset_v1.pkl')\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_df.loc[9,'processed_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text of single tweet\n",
    "- architettura modello\n",
    "- da testo a embedding \n",
    "- tuning hyperparametri \n",
    "- motivare : dropout, weight decay, class imbalance  \n",
    "- risultati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text of single tweet + text features \n",
    "- Perchè utilizziamo delle feature ( la LSTM non considera troppo elementi statistici del testo come RT, hashtag, numeri di cose, ecc..)\n",
    "- Come le passiamo: struttura modello + zscore \n",
    "- Feature utilizzate:\n",
    "    - Is retweet? Yes/No\n",
    "    - N° of URLs, tags, hashtags, cashtag, currency simbols, emails, numbers, emoticons, emojis, stopwords, punctuation\n",
    "- Perchè queste feature? rilevanza, analisi di correlazione\n",
    "- Esempi di tweet che mostrano la rilevanza delle feature (i bot tendono a avere più citazioni, hashtag, boh ) risultati \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_df = pd.read_pickle(ut.DATA_FOLDER / 'processed_dataset_v2.pkl')\n",
    "text_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "cor = text_features_df.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\t# configure to select all features\n",
    "\tfs = SelectKBest(score_func=f_classif, k='all')\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(X_train, y_train)\n",
    "\t# transform train input data\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\t# transform test input data\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['is_rt','url_c','tag_c','hashtag_c','cashtag_c','money_c','email_c','number_c','emoji_c','emoticon_c','len_tweet','stopwords_c','punct_c']\n",
    "train_ds = text_features_df[text_features_df['split'] == 'train'].reset_index(drop=True)\n",
    "val_ds = text_features_df[text_features_df['split'] == 'val'].reset_index(drop=True)\n",
    "test_ds = text_features_df[text_features_df['split'] == 'test'].reset_index(drop=True)\n",
    "\n",
    "X_train = train_ds[feature_columns]\n",
    "y_train = train_ds['label']\n",
    "\n",
    "X_test = val_ds[feature_columns]\n",
    "y_test = val_ds['label']\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint(f'{i} -> {feature_columns[i]}: {fs.scores_[i]/sum(fs.scores_)*100:.3f}%')\n",
    "# plot the scores\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come è possibile vedere, la feature 'is_rt' (Is retweet? Yes/No) sia molto correlata al valore della label (Bot/Human). Andiamo pertanto ad analizzare le percentuali che caratterizzano la differenza tra tweet prodotti da bot che sono retweet o post 'nuovi'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rt_bot = text_features_df[(text_features_df['is_rt'] == 1.0) & (text_features_df['label'] == 1.0)].shape[0]\n",
    "num_nort_bot = text_features_df[(text_features_df['is_rt'] == 0.0) & (text_features_df['label'] == 1.0)].shape[0]\n",
    "num_tweets = text_features_df.shape[0]\n",
    "print(f'Number of tweets from bots which are retweet: {num_rt_bot} - ({num_rt_bot/num_tweets*100:.1f}%)')\n",
    "print(f'Number of tweets from bots which are not retweet: {num_nort_bot} - ({num_nort_bot/num_tweets*100:.1f}%)\\n')\n",
    "\n",
    "num_rt_human = text_features_df[(text_features_df['is_rt'] == 1.0) & (text_features_df['label'] == 0.0)].shape[0]\n",
    "num_nort_human = text_features_df[(text_features_df['is_rt'] == 0.0) & (text_features_df['label'] == 0.0)].shape[0]\n",
    "print(f'Number of tweets from humans which are retweet: {num_rt_human} - ({num_rt_human/num_tweets*100:.1f}%)')\n",
    "print(f'Number of tweets from humans which are not retweet: {num_nort_human} - ({num_nort_human/num_tweets*100:.1f}%)\\n')\n",
    "\n",
    "print(f\"Pearson Correlation:\\n{text_features_df[['is_rt','label']].corr()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quindi c'è una probabilità doppia che se il tweet è un retweet l'utente sia in realtà un bot.\n",
    "\n",
    "Andiamo ora invece ad effettuare lo stesso studio sulla feature 'cashtag_c', che mostra il numero di cashtag all'interno di ogni singolo tweet e che appare molto poco correlata alla label finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pearson Correlation:\\n{text_features_df[['cashtag_c','label']].corr()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine andiamo a comparare la media di url utilizzati per singolo tweet da bot e umani con la corrispondente media di hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_url_bot = text_features_df[text_features_df['label'] == 1.0]['url_c'].mean()\n",
    "mean_url_nobot = text_features_df[text_features_df['label'] == 0.0]['url_c'].mean()\n",
    "print(f\"Average z-score of URLs per single tweet by bot user: {mean_url_bot:.3f}\")\n",
    "print(f\"Average z-score of URLs per single tweet by human user: {mean_url_nobot:.3f}\")\n",
    "print(f\"Difference: {abs(mean_url_bot - mean_url_nobot):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hashtag_bot = text_features_df[text_features_df['label'] == 1.0]['hashtag_c'].mean()\n",
    "mean_hashtag_nobot = text_features_df[text_features_df['label'] == 0.0]['hashtag_c'].mean()\n",
    "print(f\"Average z-score of hashtags per single tweet by bot user: {mean_hashtag_bot:.3f}\")\n",
    "print(f\"Average z-score of hashtags per single tweet by human user: {mean_hashtag_nobot:.3f}\")\n",
    "print(f\"Difference: {abs(mean_hashtag_bot - mean_hashtag_nobot):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il margine è nettamente più ampio (più del doppio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('twebot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e66f267e62df30a19496c87edf4ee02f643c0c674deb1d9d6ade2624584bc1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
